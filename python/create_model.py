import pandas as pd
import xgboost as xgb
import sklearn
import argparse

parser = argparse.ArgumentParser(description='Train model for cryptocurrency.')
parser.add_argument("-s", help="symbol of currency", type=str)

args = parser.parse_args()
symbol = args.s.strip()

short_window_size = 2
long_window_size = 5


def get_predictor(data):
    predictors = pd.DataFrame({"open_sma": data.open.rolling(window=short_window_size).mean(),
                               "open_smal": data.open.rolling(window=long_window_size).mean(),

                               "low_sma": data.low.rolling(window=short_window_size).mean(),
                               "low_smal": data.low.rolling(window=long_window_size).mean(),

                               "close_sma": data.close.rolling(window=short_window_size).mean(),
                               "close_smal": data.close.rolling(window=long_window_size).mean(),

                               "high_sma": data.high.rolling(window=short_window_size).mean(),
                               "high_smal": data.high.rolling(window=long_window_size).mean(),

                               "spread_sma": data.spread.rolling(window=short_window_size).mean()})

    # additional features
    #predictors["spread_rel"] = data.spread_sma / data.open_sma + 0.0001  # avoid null division
    predictors["volume"] = data.volume + 0.001  # avoid null division
    predictors["spreadrel"] = data.spread / (data.open + 0.0001)

    # The rows with nulls generated by rolling values will be removed.
    predictors = predictors.dropna()

    return predictors


def get_x_and_y(p):
    target = pd.DataFrame({"low_value": ((p.low_sma.shift(-1) - p.low_sma) + (p.low_smal.shift(-1) - p.low_smal)) / 2,
                           "open_value": ((p.open_sma.shift(-1) - p.open_sma) + (p.open_smal.shift(-1) - p.open_smal)) / 2,
                           "close_value": ((p.close_sma.shift(-1) - p.close_sma) + (p.close_smal.shift(-1) - p.close_smal)) / 2,
                           "high_value": ((p.high_sma.shift(-1) - p.high_sma) + (p.high_smal.shift(-1) - p.high_smal)) / 2,
                           "relspread": (p.spreadrel),
                           "difvolume": (p.volume / p.volume.shift(-1))}).dropna()

    X = pd.merge(p, target, left_index=True, right_index=True)[p.columns]
    y = pd.merge(p, target, left_index=True, right_index=True)[target.columns]

    return X, y


MAIN_DATA = pd.read_csv("data/data-" + symbol + ".csv", sep=",", header=0, decimal='.')
MAIN_DATA = MAIN_DATA.set_index("date")

predictor = get_predictor(MAIN_DATA)
X, y = get_x_and_y(predictor)

train_samples = int(X.shape[0] * 1)
last_10_entries = int(X.shape[0] - 10)

X_train = X.iloc[:last_10_entries]
y_train = y.iloc[:last_10_entries]

#regressorLow = xgb.XGBRegressor(gamma=0.0, n_estimators=100, base_score=0.7, colsample_bytree=1, learning_rate=0.01)
regressorLow = xgb.XGBRegressor(gamma=0.0, n_estimators=200, base_score=0.5, colsample_bytree=0.7, learning_rate=0.2, max_depth=5, objective="reg:linear")
xgbModelLow = regressorLow.fit(X_train, y_train.low_value)

regressorHigh = xgb.XGBRegressor(gamma=0.0, n_estimators=200, base_score=0.5, colsample_bytree=0.7, learning_rate=0.2, max_depth=5, objective="reg:linear")
xgbModelHigh = regressorLow.fit(X_train, y_train.high_value)

regressorOpen = xgb.XGBRegressor(gamma=0.0, n_estimators=200, base_score=0.5, colsample_bytree=0.7, learning_rate=0.2, max_depth=5, objective="reg:linear")
xgbModelOpen = regressorLow.fit(X_train, y_train.open_value)

regressorClose = xgb.XGBRegressor(gamma=0.0, n_estimators=200, base_score=0.5, colsample_bytree=0.7, learning_rate=0.2, max_depth=5, objective="reg:linear")
xgbModelClose = regressorLow.fit(X_train, y_train.close_value)

regressorSpread = xgb.XGBRegressor(gamma=0.0, n_estimators=100, base_score=0.7, colsample_bytree=1, learning_rate=0.2, max_depth=9)
xgbModelSpread = regressorSpread.fit(X_train, y_train.relspread)

#regressorVolume = xgb.XGBRegressor(gamma=0.0, n_estimators=20, base_score=0.7, colsample_bytree=1, learning_rate=0.01)
#xgbModelVolume = regressorVolume.fit(X_train, y_train.difvolume)

n = len(MAIN_DATA) - (long_window_size + 2)
p = -1 * (long_window_size + 2)
last_set = MAIN_DATA.iloc[p:]
org_length = len(last_set)
i = -1
any_results_flag = False

for y in range(25):
    X_test, y_test = get_x_and_y(get_predictor(last_set))
    if not X_test.empty:
        any_results_flag = True
        last_entry = last_set.iloc[-1:].iloc[0]

        #new_rel_spread = 1
        #if last_entry.low != 0:
         #   new_rel_spread = (last_entry.spread / last_entry.low) - xgbModelSpread.predict(X_test)[-1]
            #new_rel_spread = (xgbModelSpread.predict(X_test)[-1] * (last_entry.spread / last_entry.low))

        new_rel_spread = xgbModelSpread.predict(X_test)[-1]
        new_low = max(last_entry.low - xgbModelLow.predict(X_test)[-1], 0.0)
        new_spread = new_rel_spread * new_low

        # avoid overspread
        if new_spread > new_low:
            new_spread = new_low / 2

        new_open = max(last_entry.open - xgbModelOpen.predict(X_test)[-1], 0.0)
        new_close = max(last_entry.close - xgbModelClose.predict(X_test)[-1], 0.0)

        #new_volume = round(last_entry.volume * xgbModelVolume.predict(X_test)[-1])
        new_volume = last_entry.volume

        new_high = max(((last_entry.low + new_spread) + (last_entry.high - xgbModelHigh.predict(X_test)[-1])) / 2, 0.0)
        new_low, new_high = sorted([new_low, new_high]) # ensure low is smaller high
        new_spread = new_high - new_low

        last_set = last_set.append(pd.Series({
            "open": round(new_open, 6),
            "close": round(new_close, 6),
            "high": round(new_high, 6),
            "low": round(new_low, 6),
            "spread": round(new_spread, 6),
            "volume": round(new_volume)
        }, name=last_set.iloc[-1:].index.values[0] + 86400000), ignore_index=False)

if any_results_flag:
    last_set.iloc[org_length:].to_csv("data/predict-low-high-" + symbol + ".csv", sep=",", header=True, decimal='.', float_format='%f')
